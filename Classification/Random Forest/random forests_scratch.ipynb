{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example I'll be using [Kaggles Titanic](https://www.kaggle.com/c/titanic) dataest. This dataset is incredibly simple and will be useful for demonstrating how the model works in its entirety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datast consists of simple attributes for each passenger like their age, sex, social class, # of family members, and where they embarked. The objective is for us to predict whether a passenger survived the titanic crash or not where 1 denotes that the passenger survived and 0 denotes that they perished\n",
    "\n",
    "Something important to note is that random forests don't handle missing values. This requires us to have make some preprocessing steps before training the model, for simplicity I will just be replacing missing values with the avarage or mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['Age'].isnull(),'Age'] = np.round(df['Age'].mean())\n",
    "df.loc[df['Embarked'].isnull(),'Embarked'] = df['Embarked'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example I'm going to be using the 7 features: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "Lets split the data into a training and testing set so we can validate our models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Pclass','Sex','Age','SibSp','Parch', 'Fare', 'Embarked']\n",
    "nb_train = int(np.floor(0.9 * len(df)))\n",
    "df = df.sample(frac=1, random_state=217)\n",
    "X_train = df[features][:nb_train]\n",
    "y_train = df['Survived'][:nb_train].values\n",
    "X_test = df[features][nb_train:]\n",
    "y_test = df['Survived'][nb_train:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "The most commonly used measurements for constructing binary decision trees are: Entropy, Classification Error, and Gini index. In this thread we'll be focusing on **entropy**, which a measurement of *impurity* (uncertainty) that uses the following formula\n",
    "\n",
    "$$H(X) = -\\sum_{j}p_j\\log p_j$$\n",
    "such that $p_j$ is the probability of class $j$. In the case of binary classification entropy takes on the form\n",
    "\n",
    "$$H(X) = -p\\log_2p-(1-p)\\log_2(1-p)$$ \n",
    "\n",
    "where $p$ denotes $P(X=1)$ (the probablity that a passenger survived). Also note that in the case of binary classification we use $\\log_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(0.0, 1.01, 0.01)\n",
    "y = [entropy(p) if p != 0 else 0 for p in x]\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=15) \n",
    "matplotlib.rc('ytick', labelsize=15) \n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.set_xticklabels([0,'', '', '','', 0.5, '','','','',1],)\n",
    "ax.set_yticklabels([0,'', '', '','', 0.5, '','','','',1])\n",
    "plt.plot(x,y,linewidth=3);\n",
    "ax.grid()\n",
    "plt.xlabel('P(X=1)', fontsize=20);\n",
    "plt.ylabel('H(X)', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have the following data data {$(\\vec{x}_1,y_1),(\\vec{x}_2,y_2),..,(\\vec{x}_n,y_n)$} where each $\\vec{x}_i$ represents a feature vector $[x_{i1},x_{i2},...,x_{im}]$ and let $B$ be the number of trees we want to construct in our forest. We will do the following,\n",
    "\n",
    "1. for $b=1$ to $B$:\n",
    "    1. Draw a bootstrap sample of size *n* from the data\n",
    "    \n",
    "    2. Grow a decision tree $T_b$ from our bootstrapped sample, by repeating the following steps until the each node consists of 1 class only or until we've reached the minimum node size $\\min_{size}$ specified beforehand \n",
    "        \n",
    "         i. sample $m=\\sqrt{p}$ features (where $p$ is the number of features in our dataset)\n",
    "      \n",
    "        ii. compute the information gain for each possible value among the bootstrapped data and $m$ features\n",
    "      \n",
    "        iii. split the into 2 children nodes\n",
    "\n",
    "2. Output the ensemble of trees $\\{T\\}^B_1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first define ```entropy``` and ```information_gain``` which we will help us in finding the best split point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    elif p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
    "    \n",
    "def information_gain(left_child, right_child):\n",
    "    parent = left_child + right_child\n",
    "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "    IG_p = entropy(p_parent)\n",
    "    IG_l = entropy(p_left)\n",
    "    IG_r = entropy(p_right)\n",
    "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ```entropy``` takes in a probability of a class within a node and ```information_gain``` takes in a list of the classes from the left and right child and returns the information gain of that particular split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also define a ```draw_bootstrap``` function that can take in the training input $X$ in the form of a dataframe and also the output $y$ in the form of an array. We'll have it return the bootstrap sampled $X_{boot}$ and $y_{boot}$ that we'll use to construct a tree. We'll also return the out of bag observations that were left out for training which we'll call ```X_oob``` and ```y_oob```. At each new iteration we'll use the OOB samples to evaluate the performance of the tree built with the bootstrapped data. So in other words if we have 100 trees we'll have 100 OOB scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    X_oob = X_train.iloc[oob_indices].values\n",
    "    y_oob = y_train[oob_indices]\n",
    "    return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
    "\n",
    "def oob_score(tree, X_test, y_test):\n",
    "    mis_label = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = predict_tree(tree, X_test[i])\n",
    "        if pred != y_test[i]:\n",
    "            mis_label += 1\n",
    "    return mis_label / len(X_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define ```find_split_point``` which does the following:\n",
    "1. select $m$ features at random\n",
    "2. for each feature selected iterate through each value in the bootstrapped dataset and compute the information gain\n",
    "3. Return a dictionary which will represent a node within a tree that contains:\n",
    "\n",
    "    - the feature index \n",
    "    \n",
    "    - the value to split at \n",
    "    \n",
    "    - left child node\n",
    "    \n",
    "    - right child node\n",
    "\n",
    " produced from the split point with the **highest** information gain. It's important to note that each child node will be stored as a dictionary with the input $X_{boot}$ as ```X_bootstrap``` and outputs $y_{boot}$ as ```y_bootstrap```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_split_point(X_bootstrap, y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "    \n",
    "    while len(feature_ls) <= max_features:\n",
    "        feature_idx = random.sample(range(num_features), 1)\n",
    "        if feature_idx not in feature_ls:\n",
    "            feature_ls.extend(feature_idx)\n",
    "    \n",
    "    best_info_gain = -999\n",
    "    node = None\n",
    "    for feature_idx in feature_ls:\n",
    "        for split_point in X_bootstrap[:,feature_idx]:\n",
    "            left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "            right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "            \n",
    "            # split children for continuous variables\n",
    "            if type(split_point) in [int, float]:\n",
    "                for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                    if value <= split_point:\n",
    "                        left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                    else:\n",
    "                        right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "            # split children for categoric variables\n",
    "            else:\n",
    "                for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                    if value == split_point:\n",
    "                        left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                    else:\n",
    "                        right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                        right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "            \n",
    "            split_info_gain = information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
    "            if split_info_gain > best_info_gain:\n",
    "                best_info_gain = split_info_gain\n",
    "                left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "                right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "                node = {'information_gain': split_info_gain, \n",
    "                        'left_child': left_child, \n",
    "                        'right_child': right_child, \n",
    "                        'split_point': split_point,\n",
    "                        'feature_idx': feature_idx}\n",
    "                \n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll next need a function that decides when to stop splitting nodes in a tree and finally output a terminal node (whether the passengers survives or perishes). On a single tree ```split_node``` works as follows:\n",
    "\n",
    "   1. Given a node, store the left and right children as ```left_child``` & ```right_child``` and remove them from the original dictionary\n",
    "   2. Check if either children has 0 observations in them. If one of the children is entirely empty this ultimately means that the best split in the data for that node was unable to differentiate the 2 classes and its best to call ```terminal_node``` and return the tree. ```terminal_node``` returns the class with the highest counts at the current node. \n",
    "   3. Check if the current depth of the tree has reached the maximum depth. If so, create a terminal node and return the tree\n",
    "   4. Check if number of observations in the left child at the current node is less than the minimum samples needed to make a split which will be stored as ```min_samples_split```. If so create a terminal node and return the tree\n",
    "   5. If the left has more observations than ```min_samples_split``` we'll feed the current node into ```find_split_point``` again to find the best split point and repeat steps 1 - 6. This is ultimately going to be nesting dictionaries, which we are using to represent a node in our tree.\n",
    "   6. Repeat steps 4 and 5 for the right child node \n",
    "   7. Repeat steps 1 - 6 until each branch has a terminal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def terminal_node(node):\n",
    "    y_bootstrap = node['y_bootstrap']\n",
    "    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    left_child = node['left_child']\n",
    "    right_child = node['right_child']    \n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "    \n",
    "    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
    "        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return\n",
    "    \n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(left_child)\n",
    "        node['right_split'] = terminal_node(right_child)\n",
    "        return node\n",
    "    \n",
    "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters:\n",
    "- n_estimators: (int) The number of trees in the forest.\n",
    "- max_features: (int) The number of features to consider when looking for the best split (typically $\\sqrt(p)$\n",
    "- max_depth: (int) The maximum depth of the tree\n",
    "- min_samples_split: (int) The minimum number of samples required to split an internal node\n",
    "\n",
    "There are others parameters to consider when building a random forest, but these 4 will be the only ones we'll focus on in this thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a single tree we'll need the $X_{boot}$ and $y_{boot}$ values from our bootstrapped data along with the max_depth, min_samples_split, and max_features parameters. We first call ```find_split_point``` to create the very first split in our tree which we'll call *root_node*. Once we have a root node we can feed it into ```split_node``` which will recusively split each internal node until each branch has a terminal node.\n",
    "\n",
    "Now that we can build a single tree we can finally build our random forest which will just be a collection of these trees. When we call ```random_forest``` we'll need to specify n_estimators, max_features, max_depth, min_samples_split. Then for each tree we've built we'll use all the observations left out of our bootstrapped data to get our OOB score and append it on to a list (I'll talk about how to compute the OOB score and predict on a single tree below). Once we've built ```n_estimators``` trees we can print the mean OOB score and return the full list of trees which will represent our ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node\n",
    "\n",
    "def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, y_bootstrap, X_oob, y_oob = draw_bootstrap(X_train, y_train)\n",
    "        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "        oob_error = oob_score(tree, X_oob, y_oob)\n",
    "        oob_ls.append(oob_error)\n",
    "    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "    return tree_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a input vector $\\vec{x}_i$ we can predict its class given a single tree with ```predict_tree```. As a single tree consists of nested dictionaries which each represent a node we can let our $\\vec{x}_i$ flow through a tree by  constantly checking if the split we're at contains another dictionary (node). Once we reach a *left_split* or *right_split* that does not contain any dictionary we've reached the terminal node and we can return the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    feature_idx = tree['feature_idx']\n",
    "    \n",
    "    if X_test[feature_idx] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the above process for an input $\\vec{x}_i$ for all the trees in our ensemble and whichever class was returned more frequently will be the class predicted from our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model built we can fit it to our training data with ```random_forest``` and predict on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB estimate: 0.29\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "max_features = 3\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "\n",
    "model = random_forest(X_train, y_train, n_estimators=10, max_features=3, max_depth=8, min_samples_split=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predict_rf(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.656\n"
     ]
    }
   ],
   "source": [
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4aff0f72f2aeaec93dbc81a814974fced90e0f9a9f249b47f10b6101dd83f9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
